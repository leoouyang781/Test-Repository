{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7: Multifactor Models and Performance Measures\n",
    "\n",
    "In Chapter 6, Capital Asset Pricing Model, we discussed the simplest one-factor linear\n",
    "model: CAPM. As mentioned, this one-factor linear model serve as a benchmark for\n",
    "more advanced and complex models. In this chapter, we will focus on the famous\n",
    "Fama-French three-factor model, Fama-French-Carhart four-factor model, and\n",
    "Fama-French five-factor model. After understanding those models, readers should\n",
    "be able to develop their own multifactor linear models, such as by adding Gross\n",
    "Domestic Product (GDP), Consumer Price Index (CPI), a business cycle indicator\n",
    "or other variables as an extra factor(s). In addition, we will discuss performance\n",
    "measures, such as the Sharpe ratio, Treynor ratio, and Jensen's alpha. In particular,\n",
    "the following topics will be covered in this chapter:\n",
    "\n",
    "• Introduction to the Fama-French three-factor model\n",
    "\n",
    "• Fama-French-Carhart four-factor model\n",
    "\n",
    "• Fama-French five-factor model\n",
    "\n",
    "• Other multiplefactor models\n",
    "\n",
    "• Sharpe ratio and Treynor ratio\n",
    "\n",
    "• Lower partial standard deviation and Sortino ratio\n",
    "\n",
    "• Jensen's alpha\n",
    "\n",
    "• How to merge different datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to the Fama-French three-factor model\n",
    "\n",
    "First let's consider the basic three-factor linear model. See my notes on google docs for the full explanation.\n",
    "\n",
    "Below, we will write some basic python code to illustrate this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.960\n",
      "Model:                            OLS   Adj. R-squared:                  0.841\n",
      "Method:                 Least Squares   F-statistic:                     8.073\n",
      "Date:                Fri, 09 Feb 2024   Prob (F-statistic):              0.252\n",
      "Time:                        12:06:52   Log-Likelihood:                 16.837\n",
      "No. Observations:                   5   AIC:                            -25.67\n",
      "Df Residuals:                       1   BIC:                            -27.24\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0336      0.013      2.518      0.241      -0.136       0.203\n",
      "x1             0.3796      0.153      2.488      0.243      -1.559       2.319\n",
      "x2             0.0589      0.160      0.368      0.775      -1.974       2.092\n",
      "x3            -0.2342      0.052     -4.524      0.139      -0.892       0.424\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   0.656\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.119\n",
      "Skew:                          -0.130   Prob(JB):                        0.942\n",
      "Kurtosis:                       2.292   Cond. No.                         19.9\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Leo/.pyenv/versions/3.10.10/lib/python3.10/site-packages/statsmodels/stats/stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 5 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "y = [0.065, 0.0265, -0.0593, -0.001,0.0346]\n",
    "x1 = [0.055, -0.09, -0.041,0.045,0.022]\n",
    "x2 = [0.025, 0.10, 0.021,0.145,0.012]\n",
    "x3= [0.015, -0.08, 0.341,0.245,-0.022]\n",
    "df= pd.DataFrame({\"y\":y,\"x1\":x1, 'x2':x2,'x3':x3})\n",
    "\n",
    "y= df['y']\n",
    "x=df[['x1','x2','x3']]\n",
    "x = sm.add_constant(x) \n",
    "\n",
    "result=sm.OLS(y,x).fit()\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should note that the textbook still assumes pandas has an OLS module, though this has been evidently deprecated in favor of statsmodel.api. WE will be using statsmodel.api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215.70734536960884\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "alpha=0.05\n",
    "dfNumerator=3\n",
    "dfDenominator=1\n",
    "f=stats.f.ppf(q=1-alpha, dfn=dfNumerator, dfd=dfDenominator)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confidence level is equal to 1 minus alpha, that is, 95% in this case. The higher\n",
    "the confidence level, the more reliable the result, such as 99% instead of 95%. The\n",
    "most-used confidence levels are 90%, 95%, and 99%. dfNumeratro (dfDenominator)\n",
    "is the degree of freedom for the numerator (denominator), which depends on the\n",
    "simple sizes. From the preceding result of OLS regression, we know that those two\n",
    "values are 3 and 1.\n",
    "\n",
    "\n",
    "From the preceding values, F=8.1 < 215.7 (critical F-value), we should accept the null\n",
    "hypothesis that all coefficients are zero, that is, the quality of the model is not good.\n",
    "On the other hand, a P-value of 0.25 is way higher the critical value of 0.05. It also\n",
    "means that we should accept the null hypothesis. This makes sense since we have\n",
    "entered those values without any meanings.\n",
    "\n",
    "\n",
    "Consider a second example that uses IBM historic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-02-02</th>\n",
       "      <td>187.100006</td>\n",
       "      <td>187.389999</td>\n",
       "      <td>185.619995</td>\n",
       "      <td>185.789993</td>\n",
       "      <td>184.111465</td>\n",
       "      <td>4054200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-05</th>\n",
       "      <td>185.509995</td>\n",
       "      <td>185.779999</td>\n",
       "      <td>183.259995</td>\n",
       "      <td>183.419998</td>\n",
       "      <td>181.762894</td>\n",
       "      <td>4379600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-06</th>\n",
       "      <td>183.550003</td>\n",
       "      <td>184.679993</td>\n",
       "      <td>183.039993</td>\n",
       "      <td>183.410004</td>\n",
       "      <td>181.752991</td>\n",
       "      <td>3337600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-07</th>\n",
       "      <td>183.339996</td>\n",
       "      <td>184.020004</td>\n",
       "      <td>182.630005</td>\n",
       "      <td>183.740005</td>\n",
       "      <td>182.080002</td>\n",
       "      <td>4841200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-08</th>\n",
       "      <td>182.630005</td>\n",
       "      <td>184.550003</td>\n",
       "      <td>181.490005</td>\n",
       "      <td>184.360001</td>\n",
       "      <td>184.360001</td>\n",
       "      <td>5161200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2024-02-02  187.100006  187.389999  185.619995  185.789993  184.111465   \n",
       "2024-02-05  185.509995  185.779999  183.259995  183.419998  181.762894   \n",
       "2024-02-06  183.550003  184.679993  183.039993  183.410004  181.752991   \n",
       "2024-02-07  183.339996  184.020004  182.630005  183.740005  182.080002   \n",
       "2024-02-08  182.630005  184.550003  181.490005  184.360001  184.360001   \n",
       "\n",
       "             Volume  \n",
       "Date                 \n",
       "2024-02-02  4054200  \n",
       "2024-02-05  4379600  \n",
       "2024-02-06  3337600  \n",
       "2024-02-07  4841200  \n",
       "2024-02-08  5161200  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "\n",
    "now = datetime.now()\n",
    "five_years_ago = now - timedelta(days=365 * 5)\n",
    "# Format the output to display only the time and year\n",
    "formatted_now = datetime(now.year, now.month, now.day)\n",
    "formatted_before = datetime(five_years_ago.year, five_years_ago.month, five_years_ago.day)\n",
    "\n",
    "stock = yf.download('IBM',start = formatted_before, end = formatted_now)\n",
    "stock.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's consider the three factor model, with Adj Close as the dependent variable and Open, High, Close as the independent ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              Adj Close   R-squared:                       0.810\n",
      "Model:                            OLS   Adj. R-squared:                  0.809\n",
      "Method:                 Least Squares   F-statistic:                     1776.\n",
      "Date:                Fri, 09 Feb 2024   Prob (F-statistic):               0.00\n",
      "Time:                        15:16:24   Log-Likelihood:                -4320.3\n",
      "No. Observations:                1258   AIC:                             8649.\n",
      "Df Residuals:                    1254   BIC:                             8669.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -48.5670      2.347    -20.689      0.000     -53.172     -43.962\n",
      "Open          -0.1932      0.207     -0.935      0.350      -0.598       0.212\n",
      "High           1.4374      0.207      6.943      0.000       1.031       1.844\n",
      "Volume       1.33e-08   7.29e-08      0.182      0.855    -1.3e-07    1.56e-07\n",
      "==============================================================================\n",
      "Omnibus:                       79.134   Durbin-Watson:                   0.047\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               68.064\n",
      "Skew:                          -0.496   Prob(JB):                     1.66e-15\n",
      "Kurtosis:                       2.439   Cond. No.                     6.46e+07\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.46e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "X = stock[['Open','High','Volume']]\n",
    "Y = stock['Adj Close']\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "result=sm.OLS(Y,X).fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first three commands import three Python modules. The command line of x=sm.\n",
    "add_constant(x) will add a column of 1s. If the line is missing, we would force a\n",
    "zero intercept. To enrich our experience of running a three-factor linear model, this\n",
    "time, a different OLS function is applied. The advantage of using the statsmodels.\n",
    "apilsm.OLS() function is that we could find more information about our results,\n",
    "such as Akaike Information Criterion (AIC), Bayesian Information Criterion (BIC),\n",
    "skew, and kurtosis. The discussion of their definitions will be postponed to the next\n",
    "chapter (Chapter 8, Time-Series Analysis). The corresponding output after running the\n",
    "preceding Python program is given here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fama-French three-factor model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Merge Datasets\n",
    "\n",
    "Consider the following code as a means to merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy as s\n",
    "x= pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "    'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "    'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "\n",
    "y = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K6'],\n",
    "    'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "    'D': ['D0', 'D1', 'D2', 'D3']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3)\n",
      "  key   A   B\n",
      "0  K0  A0  B0\n",
      "1  K1  A1  B1\n",
      "2  K2  A2  B2\n",
      "3  K3  A3  B3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k4/npf5jb1d4x13y6z87pdgxb9m0000gp/T/ipykernel_84647/3160869111.py:1: DeprecationWarning: scipy.shape is deprecated and will be removed in SciPy 2.0.0, use numpy.shape instead\n",
      "  print(s.shape(x))\n"
     ]
    }
   ],
   "source": [
    "print(s.shape(x))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3)\n",
      "  key   C   D\n",
      "0  K0  C0  D0\n",
      "1  K1  C1  D1\n",
      "2  K2  C2  D2\n",
      "3  K6  C3  D3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k4/npf5jb1d4x13y6z87pdgxb9m0000gp/T/ipykernel_84647/3132444424.py:1: DeprecationWarning: scipy.shape is deprecated and will be removed in SciPy 2.0.0, use numpy.shape instead\n",
      "  print(s.shape(y))\n"
     ]
    }
   ],
   "source": [
    "print(s.shape(y))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now assume we want to merge these two datasets using the common column \"key\". Since the common values of this variable are K0, K1\n",
    "and K2. The final result should have three rows and five columns since K3 and K6\n",
    "are not the common values by the two datasets; see the result shown here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key   A   B   C   D\n",
      "0  K0  A0  B0  C0  D0\n",
      "1  K1  A1  B1  C1  D1\n",
      "2  K2  A2  B2  C2  D2\n"
     ]
    }
   ],
   "source": [
    "result = pd.merge(x,y, on='key')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, key was not duplicated when merged. Note that the merge function can be further expanded upon to include various joins - full / outer, inner, left, and right. The format of an inner join demands both datasets have the same items. An analogy\n",
    "is students from a family with both parents. The left join is based on the left dataset.\n",
    "In other words, our benchmark is the first dataset (left). An analogy is choosing\n",
    "students from families with a mum. The right is the opposite of the left, that is, the\n",
    "benchmark is the second dataset (right). The outer is the full dataset which contain\n",
    "both datasets, the same as students from all families: with both parents, with mum\n",
    "only, and with dad only. We illustrate an example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   YEAR  IBM   WMT     C  SP500\n",
      "0  2011 -0.3  0.00  0.12   0.10\n",
      "1  2013 -0.2  0.23  0.23   0.17\n",
      "   YEAR   IBM   WMT     C  SP500\n",
      "0  2010  0.20  0.10   NaN    NaN\n",
      "1  2011 -0.30  0.00  0.12   0.10\n",
      "2  2012  0.13  0.05   NaN    NaN\n",
      "3  2013 -0.20  0.23  0.23   0.17\n",
      "4  2014   NaN   NaN  0.11  -0.05\n",
      "5  2015   NaN   NaN -0.10   0.13\n",
      "   YEAR   IBM   WMT     C  SP500\n",
      "0  2010  0.20  0.10   NaN    NaN\n",
      "1  2011 -0.30  0.00  0.12   0.10\n",
      "2  2012  0.13  0.05   NaN    NaN\n",
      "3  2013 -0.20  0.23  0.23   0.17\n",
      "   YEAR  IBM   WMT     C  SP500\n",
      "0  2011 -0.3  0.00  0.12   0.10\n",
      "1  2013 -0.2  0.23  0.23   0.17\n",
      "2  2014  NaN   NaN  0.11  -0.05\n",
      "3  2015  NaN   NaN -0.10   0.13\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy as sp\n",
    "x= pd.DataFrame({'YEAR': [2010,2011, 2012, 2013],\n",
    "    'IBM': [0.2, -0.3, 0.13, -0.2],\n",
    "    'WMT': [0.1, 0, 0.05, 0.23]})\n",
    "y = pd.DataFrame({'YEAR': [2011,2013,2014, 2015],\n",
    "    'C': [0.12, 0.23, 0.11, -0.1],\n",
    "    'SP500': [0.1,0.17, -0.05, 0.13]})\n",
    "\n",
    "print(pd.merge(x,y, on='YEAR'))\n",
    "print(pd.merge(x,y, on='YEAR',how='outer'))\n",
    "print(pd.merge(x,y, on='YEAR',how='left'))\n",
    "print(pd.merge(x,y, on='YEAR',how='right'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the common variable has different names in those two datasets, we should\n",
    "specify their names by using left_on='left_name' and right_on='another_\n",
    "name'; see the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   YEAR  IBM   WMT  date     C  SP500\n",
      "0  2011 -0.3  0.00  2011  0.12   0.10\n",
      "1  2013 -0.2  0.23  2013  0.23   0.17\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy as sp\n",
    "x= pd.DataFrame({'YEAR': [2010,2011, 2012, 2013],\n",
    "    'IBM': [0.2, -0.3, 0.13, -0.2],\n",
    "    'WMT': [0.1, 0, 0.05, 0.23]})\n",
    "y = pd.DataFrame({'date': [2011,2013,2014, 2015],\n",
    "    'C': [0.12, 0.23, 0.11, -0.1],\n",
    "    'SP500': [0.1,0.17, -0.05, 0.13]})\n",
    "print(pd.merge(x,y, left_on='YEAR',right_on='date'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we intend to merge based on the index (row numbers), we specify that left_\n",
    "index='True', and right_index='True'; see the following code. In a sense, since\n",
    "both datasets have four rows, we simply put them together, row by row. The true\n",
    "reason is that for those two datasets, there is no specific index. For a comparison, the\n",
    "ffMonthly.pkl data has the date as its index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   YEAR   IBM   WMT  date     C  SP500\n",
      "0  2010  0.20  0.10  2011  0.12   0.10\n",
      "1  2011 -0.30  0.00  2013  0.23   0.17\n",
      "2  2012  0.13  0.05  2014  0.11  -0.05\n",
      "3  2013 -0.20  0.23  2015 -0.10   0.13\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy as sp\n",
    "x= pd.DataFrame({'YEAR': [2010,2011, 2012, 2013],\n",
    "    'IBM': [0.2, -0.3, 0.13, -0.2],\n",
    "    'WMT': [0.1, 0, 0.05, 0.23]})\n",
    "y = pd.DataFrame({'date': [2011,2013,2014, 2015],\n",
    "    'C': [0.12, 0.23, 0.11, -0.1],\n",
    "    'SP500': [0.1,0.17, -0.05, 0.13]})\n",
    "print(pd.merge(x,y, right_index=True,left_index=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
